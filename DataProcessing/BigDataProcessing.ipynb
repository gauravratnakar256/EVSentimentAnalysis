{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e57d0017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "#sqlContext = SQLContext(sc)\n",
    "from nltk.corpus import stopwords\n",
    "import re as re\n",
    "from pyspark.ml.feature import CountVectorizer , IDF\n",
    "from pyspark.mllib.linalg import Vector, Vectors\n",
    "#from pyspark.mllib.clustering import LDA, LDAModel\n",
    "from pyspark.ml.clustering import LDA, LDAModel\n",
    "import nltk\n",
    "import numpy as np\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import size\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.ml.feature import RegexTokenizer,StopWordsRemover\n",
    "from pyspark.sql.functions import udf, struct\n",
    "import pyspark.sql.types as T \n",
    "import string\n",
    "import nltk\n",
    "from pyspark.sql import Row\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6174cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "21/12/10 09:10:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/12/10 09:10:01 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "spark =SparkSession.builder.master(\"local[1]\").appName('SparkProject').getOrCreate() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45b3c4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#data  = spark.read.json(r\"C:\\Users\\EndUser\\Desktop\\Data\\AbhishekData\\tweets.json\")\n",
    "#df = spark.read.json(\"tweets2.csv\")\n",
    "df = spark.read.json(\"tweets90.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6550ec49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(content='.@VW will introduce heads-up display with augmented-reality in its upcoming #EVs. https://t.co/CINqosgiCD', date='2017-01-31T23:49:34+00:00', latitude=None, longitude=None, tweetid=826578200402616320, userid=1187313746, userlocation='')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8de28195",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropDuplicates(['tweetid'])\n",
    "df = df.na.drop()\n",
    "df = df.filter(\"content != ''\")\n",
    "df = df.limit(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bce3d734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)\n",
    "\n",
    "def remove_number(tweet):\n",
    "    tweet = re.sub('([0-9]+)', '', tweet) \n",
    "    return tweet\n",
    "\n",
    "def remove_users(tweet):\n",
    "    tweet = re.sub('(RT\\s@[A-Za-z]+[A-Za-z0-9-_]+)', '', tweet) \n",
    "    tweet = re.sub('(@[A-Za-z]+[A-Za-z0-9-_]+)', '', tweet) \n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90dcef85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "\n",
    "remove_emoji=udf(remove_emoji)\n",
    "remove_users=udf(remove_users)\n",
    "remove_number=udf(remove_number)\n",
    "\n",
    "df=df.withColumn('content', remove_emoji(df['content']))\n",
    "df=df.withColumn('content', remove_users(df['content']))\n",
    "df=df.withColumn('content', remove_number(df['content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d39bd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.withColumn('content', F.regexp_replace('content', r'http\\S+', ''))\n",
    "df = df.withColumn('content', F.regexp_replace('content', '@\\w+', ''))\n",
    "df = df.withColumn('content', F.regexp_replace('content', '#', ''))\n",
    "df = df.withColumn('content', F.regexp_replace('content', 'RT', ''))\n",
    "df = df.withColumn('content', F.regexp_replace('content', ':', ''))\n",
    "df = df.withColumn('content', F.regexp_replace('content', '\\n', ''))\n",
    "df = df.withColumn('content', F.regexp_replace('content', '|', ''))\n",
    "df = df.withColumn('content', F.regexp_replace('content', '[^\\sa-zA-Z0-9]', ''))\n",
    "df = df.withColumn(\"content\",F.lower('content'))\n",
    "df = df.withColumn(\"content\",F.rtrim('content'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae5bbbc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(content=' european fast charging networks announce fast charging alliance evs', date='2017-02-12T19:18:39+00:00', latitude=59.8097794, longitude=10.4914682, tweetid=830858673421443077, userid=1664893472, userlocation='üìçAmsterdam & Costa Rica ')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0f75d49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexTokenizer().setPattern(\"[\\\\W_]+\").setMinTokenLength(3).setInputCol(\"content\").setOutputCol(\"tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1b7bfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tokenizer.transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b483f6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(content=' european fast charging networks announce fast charging alliance evs', date='2017-02-12T19:18:39+00:00', latitude=59.8097794, longitude=10.4914682, tweetid=830858673421443077, userid=1664893472, userlocation='üìçAmsterdam & Costa Rica ', tokens=['european', 'fast', 'charging', 'networks', 'announce', 'fast', 'charging', 'alliance', 'evs'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fdab20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/bigdata/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwordList = stopwords.words('english')\n",
    "remover = StopWordsRemover(stopWords=stopwordList)\n",
    "remover.setInputCol(\"tokens\")\n",
    "remover.setOutputCol(\"filtered\")\n",
    "\n",
    "df = remover.transform(df);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0406138f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/bigdata/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatization(row):\n",
    "    #row = [stemmer.stem(lemmatizer.lemmatize(word)) for word in row]\n",
    "    row = [lemmatizer.lemmatize(word,'v') for word in row]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6bbdf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatization = udf(lemmatization)\n",
    "\n",
    "df=df.withColumn('tokens', lemmatization(df['filtered']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5d194fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(content=' european fast charging networks announce fast charging alliance evs', date='2017-02-12T19:18:39+00:00', latitude=59.8097794, longitude=10.4914682, tweetid=830858673421443077, userid=1664893472, userlocation='üìçAmsterdam & Costa Rica ', tokens='[european, fast, charge, network, announce, fast, charge, alliance, evs]', filtered=['european', 'fast', 'charging', 'networks', 'announce', 'fast', 'charging', 'alliance', 'evs'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "473f7ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sampling data for manual labelling\n",
    "def get_sample(part=0.17):\n",
    "    df = df.sample(part)\n",
    "    df = df.select(\"tweetid\", \"content\")\n",
    "    df.coalesce(1).write.option(\"header\", True).csv('sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2833b86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62ee5ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training and topic modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9447b7",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import lit\n",
    "df = df.withColumn(\"polarity\", lit(0))\n",
    "df = df.withColumn(\"topic\", lit(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1eac14d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(content=' european fast charging networks announce fast charging alliance evs', date='2017-02-12T19:18:39+00:00', latitude=59.8097794, longitude=10.4914682, tweetid=830858673421443077, userid=1664893472, userlocation='üìçAmsterdam & Costa Rica ', tokens='[european, fast, charge, network, announce, fast, charge, alliance, evs]', filtered=['european', 'fast', 'charging', 'networks', 'announce', 'fast', 'charging', 'alliance', 'evs'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ec53d8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting tweet sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53d394ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(x)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "sentiment_polarity = udf(lambda x: TextBlob(x).sentiment[0])\n",
    "spark.udf.register(\"sentiment_polarity\", sentiment_polarity)\n",
    "\n",
    "sentiment_subjectivity = udf(lambda x: TextBlob(x).sentiment[1])\n",
    "spark.udf.register(\"sentiment_subjectivity\", sentiment_subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a079c721",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(content=' european fast charging networks announce fast charging alliance evs', date='2017-02-12T19:18:39+00:00', latitude=59.8097794, longitude=10.4914682, tweetid=830858673421443077, userid=1664893472, userlocation='üìçAmsterdam & Costa Rica ', tokens='[european, fast, charge, network, announce, fast, charge, alliance, evs]', filtered=['european', 'fast', 'charging', 'networks', 'announce', 'fast', 'charging', 'alliance', 'evs'], sentiment_polarity=0.13333333333333333)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.withColumn('sentiment_polarity',sentiment_polarity('content').cast('double'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a226f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(content=' european fast charging networks announce fast charging alliance evs', date='2017-02-12T19:18:39+00:00', latitude=59.8097794, longitude=10.4914682, tweetid=830858673421443077, userid=1664893472, userlocation='üìçAmsterdam & Costa Rica ', tokens='[european, fast, charge, network, announce, fast, charge, alliance, evs]', filtered=['european', 'fast', 'charging', 'networks', 'announce', 'fast', 'charging', 'alliance', 'evs'], sentiment_polarity=0.13333333333333333, sentiment_subjectivity=0.39999999999999997)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.withColumn('sentiment_subjectivity',sentiment_subjectivity('content').cast('double'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cea37aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac168046",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Collecting the data from spark and save to list\n",
    "words_array = df.select(\"filtered\").rdd.flatMap(lambda x: x).collect()\n",
    "txt = df.select(\"content\").rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11277372",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = corpora.Dictionary(words_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d744f8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = words_array\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "bow = corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7fdb840f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('alliance', 1),\n",
       "  ('announce', 1),\n",
       "  ('charging', 2),\n",
       "  ('european', 1),\n",
       "  ('evs', 1),\n",
       "  ('fast', 2),\n",
       "  ('networks', 1)]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing the bag of words\n",
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8cec8ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create and run the guided lda model\n",
    "def test_eta(eta, dictionary, ntopics, print_topics=True, print_dist=True):\n",
    "    corp = words_array\n",
    "    np.random.seed(42) # set the random seed for repeatability\n",
    "    bow = [dictionary.doc2bow(line) for line in corp] # get the bow-format lines with the set dictionary\n",
    "    with (np.errstate(divide='ignore')):  # ignore divide-by-zero warnings\n",
    "        model = gensim.models.ldamodel.LdaModel(\n",
    "            corpus=bow, id2word=dictionary, num_topics=ntopics,\n",
    "            random_state=42, chunksize=100, eta=eta,\n",
    "            eval_every=-1, update_every=1,\n",
    "            passes=150, alpha='auto', per_word_topics=True)\n",
    "    # visuzlize the model term topics\n",
    "    # viz_model(model, dictionary)\n",
    "    print('Perplexity: {:.2f}'.format(model.log_perplexity(bow)))\n",
    "    if print_topics:\n",
    "        # display the top terms for each topic\n",
    "        for topic in range(ntopics):\n",
    "            print('Topic {}: {}'.format(topic, [dictionary[w] for w,p in model.get_topic_terms(topic, topn=3)]))\n",
    "    if print_dist:\n",
    "        # display the topic probabilities for each document\n",
    "        for line,bag in zip(txt,bow):\n",
    "            doc_topics = ['({}, {:.1%})'.format(topic, prob) for topic,prob in model.get_document_topics(bag)]\n",
    "            print('{} {}'.format(line, doc_topics))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "328113b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create the eta for topic modelling\n",
    "def create_eta(priors, etadict, ntopics):\n",
    "    eta = np.full(shape=(ntopics, len(etadict)), fill_value=1) # create a (ntopics, nterms) matrix and fill with 1\n",
    "    for word, topic in priors.items(): # for each word in the list of priors\n",
    "        keyindex = [index for index,term in etadict.items() if term==word] # look up the word in the dictionary\n",
    "        if (len(keyindex)>0): # if it's in the dictionary\n",
    "            print(keyindex)\n",
    "            eta[topic,keyindex[0]] = 1e7  # put a large number in there\n",
    "    eta = np.divide(eta, eta.sum(axis=0)) # normalize so that the probabilities sum to 1 over all topics\n",
    "    print (eta)\n",
    "    return eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f65cce5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[492]\n",
      "[844]\n",
      "[457]\n",
      "[516]\n",
      "[203]\n",
      "[296]\n",
      "[748]\n",
      "[304]\n",
      "[744]\n",
      "[348]\n",
      "[318]\n",
      "[120]\n",
      "[555]\n",
      "[100]\n",
      "[131]\n",
      "[557]\n",
      "[317]\n",
      "[491]\n",
      "[459]\n",
      "[326]\n",
      "[268]\n",
      "[624]\n",
      "[2]\n",
      "[276]\n",
      "[[1.66666667e-01 1.66666667e-01 9.99999500e-08 ... 1.66666667e-01\n",
      "  1.66666667e-01 1.66666667e-01]\n",
      " [1.66666667e-01 1.66666667e-01 9.99999500e-08 ... 1.66666667e-01\n",
      "  1.66666667e-01 1.66666667e-01]\n",
      " [1.66666667e-01 1.66666667e-01 9.99999500e-08 ... 1.66666667e-01\n",
      "  1.66666667e-01 1.66666667e-01]\n",
      " [1.66666667e-01 1.66666667e-01 9.99999500e-08 ... 1.66666667e-01\n",
      "  1.66666667e-01 1.66666667e-01]\n",
      " [1.66666667e-01 1.66666667e-01 9.99999500e-08 ... 1.66666667e-01\n",
      "  1.66666667e-01 1.66666667e-01]\n",
      " [1.66666667e-01 1.66666667e-01 9.99999500e-01 ... 1.66666667e-01\n",
      "  1.66666667e-01 1.66666667e-01]]\n",
      "Perplexity: 11.74\n"
     ]
    }
   ],
   "source": [
    "topic_labelling = {\n",
    "    'cost': 0,'value': 0,'worth': 0,'valuation': 0,'premium': 0,'rate': 0,'overprice': 0,'cheap': 0,'discount': 0,'inflation': 0,'pay': 0,'amount': 0,'expense': 0,'expensive': 0,'dollar': 0,'money': 0,'costly': 0,'prise': 0,'priceless': 0,'undervalue': 0,'overvalue': 0,'revaluation': 0,'pennyworth': 0,'economy': 0,'underrate': 0,'underprice': 0,'profit': 0,'estimate':0 ,'fees':0 ,'marginal':0 ,'cash':0 ,'pocket':0 ,'capital':0 ,'dime':0 ,'markup':0 ,'haggle':0 ,'wholesale':0 ,'quotation':0 ,'stipend':0 ,'afford':0 ,'savings':0 ,'save':0,'range':1 ,'anxiety':1 ,'far':1 ,'distance':1 ,'long':1 ,'area':1 ,'long-range':1 ,'short-range':1 ,'travel':1 ,'near':1 ,'mileage':1 ,'afar':1 ,'farther':1 ,'reach':1 ,'remote':1 ,'short':1 ,'stretch':1 ,'haul':1 ,'distant':1 ,'commute':1 ,'extended-range':1,'fuel':2 ,'zero':2 ,'emission':2 ,'das':2 ,'diesel':2 ,'refuel':2 ,'coal':2 ,'oil ':2 ,'charcoal':2 ,'biogas':2 ,'fossil':2 ,'electric':2 ,'ev':2,'eco':3 ,'eco-friendly':3 ,'carbon':3 ,'footprint':3 ,'pollution':3 ,'sustainable':3 ,'renewal':3 ,'power':3 ,'plug':3 ,'green':3 ,'environment':3 ,'earth':3 ,'friendly':3 ,'carbon':3 ,'footprint':3,'batttery':4 ,'cell':4 ,'life':4 ,'charge':4 ,'charger':4 ,'voltage':4 ,'elctrolyte':4 ,'surcharge':4 ,'lithium-ion':4 ,'lithium':4 ,'ion':4 ,'battery cost':4 ,'battery life':4 ,'Fuel cell':4 ,'killowatt':4 ,'hour':4 ,'killowatt-hour':4 ,'regenerative':4 ,'regenerative-braking':4, 'infra':5 ,'infrastructure':5 ,'stations':5 ,'charging':5 ,'plug':5 ,'chademo':5 ,'fast charging':5 ,'supercharger':5 ,'framework':5 ,'structure':5 ,'groundwork':5 ,'support':5\n",
    "}\n",
    "eta = create_eta(topic_labelling, id2word, 6)\n",
    "lda_model = test_eta(eta, id2word, 6,False,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b0901d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
